{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Μοντέλο επιλογής:**\n",
    "Σε αυτό το ερώτημα θα επιλέξουμε το μοντέλο του *CNN*,καθώς είχε καλύτερα αποτελέσματα από αυτό του LSTM.\n",
    "\n",
    "**Περιγραφή του [5] σύνδεσμου:**\n",
    "    Το συγκεκριμένο paper \"How transferable are features in deep neural nertworks?\"  αναφέρει το κατά πόσο είναι εύλογο να εκπαιδεύσουμε ένα νευρωνικό δίκτυο σε άλλοο τασκ και να μεταφέρουμε τα βάρη του για να προβλέψουμε κάποιο άλλο. Κάποια από αυτά τα συμπεράσματα είναι τα εξής:\n",
    "\n",
    "1. Καλό είναι να χρησιμοποιούμε τα βάρη των layer που δεν είναι πολύ βαθιά καθώς είναι πιο γενικά τα χαρακτηριστικά που εξάγουν, ενώ τα τελευταία επίπεδα που είναι πιο ειδικευμένα πάνω στο τασκ που έχουνε αναλάβει , δε θα προσφέρουν πολλά στο δικό μας δίκτυο.\n",
    "2. Η μεταφορά των weights από ένα μοντέλο σε ένα άλλο και η μετεκπαίδευση τους(fine tuning) μπορεί να προσφέρει στην αποφυγή του overfit και την πραγματοποίηση του generalization, ανεξαρτήτως μεγέθους των δεδομένων μας καθώς τα βάρη που έχουμε μεταφέρει θα συνεχίσουν να είναι ίδια και στη συνέχεια. Αυτό που θα αλλάζει είναι τα επόμενα layers που θα επικεντρώνονται στο συγκεκριμένο τασκ που έχουμε.\n",
    "3. Σημαντικό είναι πως η μεθοδολογία αυτή δεν έχει πολύ νόημα αν τα tasks δε μοιάζουν μεταξύ τους.\n",
    "4. Τέλος, υπάρχει ένα ακόμα θέμα το οποίο μπορεί να φέρει επιπτώσεις στην απόδοση του transfer learning. Αυτό είναι το fragile co-adapted features, που συμβαίνει όταν τα layers του δικτύου διαμορφώνονται, κατά την εκπαίδευση αλλά ταυτόχρονα επηρεάζονται και από άλλα layers. Επομένως, όταν εμείς μεταφέρουμε αυτό το κομμάτι , πλέον δε θα έχει την ίδια αλληλεπίδραση με τα layer που είχε στο προηγούμενο δίκτυο. Αυτό το πρόβλημα αφορά κυρίως τα μεσαία layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import SubsetRandomSampler, DataLoader\n",
    "import re\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "# Combine similar classes and remove underrepresented classes\n",
    "class_mapping = {\n",
    "    'Rock': 'Rock',\n",
    "    'Psych-Rock': 'Rock',\n",
    "    'Indie-Rock': None,\n",
    "    'Post-Rock': 'Rock',\n",
    "    'Psych-Folk': 'Folk',\n",
    "    'Folk': 'Folk',\n",
    "    'Metal': 'Metal',\n",
    "    'Punk': 'Metal',\n",
    "    'Post-Punk': None,\n",
    "    'Trip-Hop': 'Trip-Hop',\n",
    "    'Pop': 'Pop',\n",
    "    'Electronic': 'Electronic',\n",
    "    'Hip-Hop': 'Hip-Hop',\n",
    "    'Classical': 'Classical',\n",
    "    'Blues': 'Blues',\n",
    "    'Chiptune': 'Electronic',\n",
    "    'Jazz': 'Jazz',\n",
    "    'Soundtrack': None,\n",
    "    'International': None,\n",
    "    'Old-Time': None\n",
    "}\n",
    "\n",
    "def torch_train_val_split(dataset, batch_train, batch_eval,val_size=.2, shuffle=True, seed=None):\n",
    "    # Creating data indices for training and validation splits:\n",
    "    dataset_size = len(dataset)\n",
    "    indices = list(range(dataset_size))\n",
    "    val_split = int(np.floor(val_size * dataset_size))\n",
    "    if shuffle:\n",
    "        np.random.seed(seed)\n",
    "        np.random.shuffle(indices)\n",
    "    train_indices = indices[val_split:]\n",
    "    val_indices = indices[:val_split]\n",
    "\n",
    "    # Creating PT data samplers and loaders:\n",
    "    train_sampler = SubsetRandomSampler(train_indices)\n",
    "    val_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "    train_loader = DataLoader(dataset,\n",
    "                              batch_size=batch_train,\n",
    "                              sampler=train_sampler)\n",
    "    val_loader = DataLoader(dataset,\n",
    "                            batch_size=batch_eval,\n",
    "                            sampler=val_sampler)\n",
    "    return train_loader, val_loader\n",
    "\n",
    "\n",
    "def read_fused_spectrogram(spectrogram_file):\n",
    "    spectrogram = np.load(spectrogram_file)\n",
    "    return spectrogram.T\n",
    "\n",
    "\n",
    "def read_mel_spectrogram(spectrogram_file):\n",
    "    spectrogram = np.load(spectrogram_file)[:128]\n",
    "    return spectrogram.T\n",
    "\n",
    "    \n",
    "def read_chromagram(spectrogram_file):\n",
    "    spectrogram = np.load(spectrogram_file)[128:]\n",
    "    return spectrogram.T\n",
    "\n",
    "\n",
    "class LabelTransformer(LabelEncoder):\n",
    "    def inverse(self, y):\n",
    "        try:\n",
    "            return super(LabelTransformer, self).inverse_transform(y)\n",
    "        except:\n",
    "            return super(LabelTransformer, self).inverse_transform([y])\n",
    "\n",
    "    def transform(self, y):\n",
    "        try:\n",
    "            return super(LabelTransformer, self).transform(y)\n",
    "        except:\n",
    "            return super(LabelTransformer, self).transform([y])\n",
    "\n",
    "\n",
    "\n",
    "class PaddingTransform(object):\n",
    "    def __init__(self, max_length, padding_value=0):\n",
    "        self.max_length = max_length\n",
    "        self.padding_value = padding_value\n",
    "    #https://stackoverflow.com/questions/9663562/what-is-the-difference-between-init-and-call\n",
    "    def __call__(self, s):\n",
    "        if len(s) == self.max_length:\n",
    "            return s\n",
    "\n",
    "        if len(s) > self.max_length:\n",
    "            return s[:self.max_length]\n",
    "\n",
    "        if len(s) < self.max_length:\n",
    "            #https://www.geeksforgeeks.org/copy-python-deep-copy-shallow-copy/\n",
    "            s1 = copy.deepcopy(s)\n",
    "            pad = np.zeros((self.max_length - s.shape[0], s.shape[1]), dtype=np.float32)\n",
    "            s1 = np.vstack((s1, pad))\n",
    "            return s1\n",
    "        \n",
    "class SpectrogramDataset(Dataset):\n",
    "    def __init__(self, path, class_mapping=None, train=True, max_length=-1, read_spec_fn=read_fused_spectrogram,sort=True):\n",
    "        t = 'train' if train else 'test'\n",
    "        p = os.path.join(path, t)\n",
    "        self.index = os.path.join(path, \"{}_labels.txt\".format(t))\n",
    "        self.files, labels = self.get_files_labels(self.index, class_mapping)\n",
    "        self.feats = [read_spec_fn(os.path.join(p, f)) for f in self.files]\n",
    "        self.feat_dim = self.feats[0].shape[1]\n",
    "        self.lengths = [len(i) for i in self.feats]\n",
    "        \n",
    "        # not working for a reason...\n",
    "        if sort:\n",
    "            self.indexes = list(range(len(self.lengths)))\n",
    "            self.indexes.sort(key=self.lengths.__getitem__, reverse=True)\n",
    "            self.lengths = list(map(self.lengths.__getitem__, self.indexes))\n",
    "            #print(self.lengths)\n",
    "            self.feats = list(map(self.feats.__getitem__, self.indexes))\n",
    "            #print([f.shape for f in self.feats] )\n",
    "            labels = list(map(labels.__getitem__, self.indexes))\n",
    "        \n",
    "        self.max_length = max(self.lengths) if max_length <= 0 else max_length\n",
    "        self.zero_pad_and_stack = PaddingTransform(self.max_length)\n",
    "        self.label_transformer = LabelTransformer()\n",
    "        if isinstance(labels, (list, tuple)):\n",
    "            self.labels = np.array(self.label_transformer.fit_transform(labels)).astype('int64')\n",
    "        #print([f.shape for f in self.feats] )\n",
    "\n",
    "    def get_files_labels(self, txt, class_mapping):\n",
    "        with open(txt, 'r') as fd:\n",
    "            lines = [l.rstrip().split('\\t') for l in fd.readlines()[1:]]\n",
    "        files, labels = [], []\n",
    "        for l in lines:\n",
    "            label = l[1]\n",
    "            if class_mapping:\n",
    "                label = class_mapping[l[1]]\n",
    "            if not label:\n",
    "                continue\n",
    "            # Kaggle automatically unzips the npy.gz format so this hack is needed\n",
    "            _id = l[0].split('.')[0]\n",
    "            npy_file = '{}.fused.full.npy'.format(_id)\n",
    "            files.append(npy_file)\n",
    "            labels.append(label)\n",
    "        return files, labels\n",
    "    \n",
    "    \n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        # TODO: Inspect output and comment on how the output is formatted\n",
    "        l = min(self.lengths[item], self.max_length)\n",
    "        return np.expand_dims(self.zero_pad_and_stack(self.feats[item]), 0), self.labels[item], l\n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort = False\n",
    "#train val set\n",
    "fused_specs = SpectrogramDataset(\n",
    "         '/kaggle/input/patreco3-multitask-affective-music/data/fma_genre_spectrograms/',\n",
    "         train=True,\n",
    "         class_mapping=class_mapping,\n",
    "         max_length=-1,\n",
    "         read_spec_fn=read_fused_spectrogram)\n",
    "\n",
    "train_loader_fused, val_loader_fused = torch_train_val_split(fused_specs, 32 ,32, val_size=.1)\n",
    "\n",
    "#test\n",
    "test_loader_fused = SpectrogramDataset(\n",
    "          '/kaggle/input/patreco3-multitask-affective-music/data/fma_genre_spectrograms/',\n",
    "         train=False,\n",
    "         class_mapping=class_mapping,\n",
    "         max_length=-1,\n",
    "         read_spec_fn=read_fused_spectrogram)\n",
    "\n",
    "dataloaders = {'train':train_loader_fused,'val':val_loader_fused}\n",
    "\n",
    "test_loader = DataLoader(test_loader_fused,batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7, verbose=False):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score:\n",
    "            self.counter += 1\n",
    "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), 'checkpoint.pt')\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class Layers(nn.Module):\n",
    "    def __init__(self,in_c,out_c):\n",
    "        super(Layers,self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels=in_c,kernel_size=5,out_channels=out_c,stride=1,padding=2)\n",
    "        self.bn = nn.BatchNorm2d(num_features=out_c)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self,x):\n",
    "        output = self.conv(x.float())\n",
    "        output = self.bn(output)\n",
    "        output = self.tanh(output)\n",
    "        output = self.pool(output)\n",
    "        return output\n",
    "\n",
    "class BasicCNN(nn.Module):\n",
    "    def __init__(self, classes):\n",
    "        super(BasicCNN, self).__init__()\n",
    "        self.classes = classes\n",
    "        self.l1 = Layers(in_c=1, out_c=16)\n",
    "        self.l2 = Layers(in_c=16, out_c=8)\n",
    "        self.l3 = Layers(in_c=8, out_c=4)\n",
    "        self.l4 = Layers(in_c=4, out_c=2)\n",
    "        self.net = nn.Sequential(self.l1, self.l2, self.l3, self.l4)\n",
    "        self.fc1 = nn.Linear(8 * 80 * 2, self.classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        output = self.net(x)\n",
    "        output = output.view(-1, 8 * 80 * 2)\n",
    "        output = self.fc1(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainCNN(model,dataloaders,num_epochs,optimizer,patience,crit=False):\n",
    "    Flag=False\n",
    "    # for loss\n",
    "    val_loss = []\n",
    "    train_loss = []\n",
    "    phase1 = dataloaders.keys()\n",
    "    if crit == True:\n",
    "        criterion = nn.MSELoss()\n",
    "    else:\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "    train_loader = dataloaders['train']\n",
    "    if(torch.cuda.is_available()):\n",
    "        device = 0\n",
    "        model.to(device)\n",
    "    else:\n",
    "        device = 'cpu'\n",
    "        model.to(device)\n",
    "    if(patience!=None):\n",
    "        earlystop = EarlyStopping(patience = patience,verbose = True)\n",
    "    for epoch in range(num_epochs):\n",
    "        counter = epoch # keeping this variable for plot function after for loop\n",
    "        if Flag == True:\n",
    "            break\n",
    "        print('Epoch:',epoch + 1)\n",
    "        epoch_metrics = {\"loss\": [], \"acc\": []}\n",
    "        for phase in phase1:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "            for  batch_idx, data in enumerate(dataloaders[phase]):\n",
    "                optimizer.zero_grad()\n",
    "                output = model(data[0].to(device)).to(device)#, data[2].to(device))  ignore the true Length\n",
    "                if crit == True:\n",
    "                    loss = criterion(output.squeeze(), data[1].to(device))\n",
    "                else:\n",
    "                    loss = criterion(output, data[1].to(device))\n",
    "                acc = 100 * (output.detach().argmax(1) == data[1].to(device)).cpu().numpy().mean()\n",
    "                epoch_metrics[\"loss\"].append(loss.item())\n",
    "                epoch_metrics[\"acc\"].append(acc)\n",
    "                sys.stdout.write(\n",
    "                \"\\r[Epoch %d/%d] [Batch %d/%d] [Loss: %f (%f), Acc: %.2f%% (%.2f%%)]\"\n",
    "                % (\n",
    "                    epoch + 1,\n",
    "                    num_epochs,\n",
    "                    batch_idx,\n",
    "                    len(dataloaders[phase]),\n",
    "                    loss.item(),\n",
    "                    np.mean(epoch_metrics[\"loss\"]),\n",
    "                    acc,\n",
    "                    np.mean(epoch_metrics[\"acc\"]),\n",
    "                    )\n",
    "                )\n",
    "\n",
    "                if(phase =='train'):\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "            \n",
    "            epoch_acc = np.mean(epoch_metrics[\"acc\"])\n",
    "            epoch_loss = np.mean(epoch_metrics[\"loss\"])\n",
    "            \n",
    "            if phase == 'train':\n",
    "                train_loss.append(epoch_loss)\n",
    "            else: \n",
    "                val_loss.append(epoch_loss)\n",
    "            if(phase == 'val' and patience !=None):\n",
    "                earlystop(epoch_loss,model)\n",
    "                if(earlystop.early_stop):\n",
    "                    print(\"Early stopping\")\n",
    "                    model.load_state_dict(torch.load('./checkpoint.pt'))\n",
    "                    print('{} Accuracy: {}'.format(phase,epoch_acc.item()))\n",
    "                    #break\n",
    "                    Flag = True\n",
    "        print('{} Accuracy: {}'.format(phase,epoch_acc.item()))\n",
    "    if counter == num_epochs -1:\n",
    "        epochs_axis = np.arange(num_epochs)\n",
    "    else:\n",
    "        epochs_axis = np.arange(counter)\n",
    "    plt.plot(epochs_axis, train_loss,color='red')\n",
    "    plt.plot(epochs_axis, val_loss,color='blue')\n",
    "    plt.legend(['training-red', 'validation-blue'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "γ) Εκπαιδεύστε αυτό το μοντέλο στο fma_genre_spectrograms dataset και αποθηκεύστε τα βάρη\n",
    "του δικτύου στην εποχή που έχει την καλύτερη επίδοση (checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "[Epoch 1/20] [Batch 7/8] [Loss: 2.026534 (2.057715), Acc: 33.33% (24.63%)]Validation loss decreased (inf --> 2.057715).  Saving model ...\n",
      "val Accuracy: 24.63216641298833\n",
      "Epoch: 2\n",
      "[Epoch 2/20] [Batch 7/8] [Loss: 2.212460 (1.849280), Acc: 33.33% (34.93%)]Validation loss decreased (2.057715 --> 1.849280).  Saving model ...\n",
      "val Accuracy: 34.929921359715884\n",
      "Epoch: 3\n",
      "[Epoch 3/20] [Batch 7/8] [Loss: 1.647306 (1.768260), Acc: 16.67% (38.04%)]Validation loss decreased (1.849280 --> 1.768260).  Saving model ...\n",
      "val Accuracy: 38.037480974124804\n",
      "Epoch: 4\n",
      "[Epoch 4/20] [Batch 7/8] [Loss: 2.007631 (1.618517), Acc: 33.33% (43.40%)]Validation loss decreased (1.768260 --> 1.618517).  Saving model ...\n",
      "val Accuracy: 43.40277777777778\n",
      "Epoch: 5\n",
      "[Epoch 5/20] [Batch 7/8] [Loss: 1.702744 (1.524578), Acc: 66.67% (48.50%)]Validation loss decreased (1.618517 --> 1.524578).  Saving model ...\n",
      "val Accuracy: 48.49854134956874\n",
      "Epoch: 6\n",
      "[Epoch 6/20] [Batch 7/8] [Loss: 1.942692 (1.443106), Acc: 33.33% (50.55%)]Validation loss decreased (1.524578 --> 1.443106).  Saving model ...\n",
      "val Accuracy: 50.551750380517504\n",
      "Epoch: 7\n",
      "[Epoch 7/20] [Batch 7/8] [Loss: 2.056911 (1.384088), Acc: 16.67% (52.88%)]Validation loss decreased (1.443106 --> 1.384088).  Saving model ...\n",
      "val Accuracy: 52.880834601725006\n",
      "Epoch: 8\n",
      "[Epoch 8/20] [Batch 7/8] [Loss: 1.901911 (1.339390), Acc: 33.33% (57.42%)]Validation loss decreased (1.384088 --> 1.339390).  Saving model ...\n",
      "val Accuracy: 57.4216768138001\n",
      "Epoch: 9\n",
      "[Epoch 9/20] [Batch 7/8] [Loss: 2.690759 (1.234240), Acc: 0.00% (60.28%)]Validation loss decreased (1.339390 --> 1.234240).  Saving model ...\n",
      "val Accuracy: 60.280314561136485\n",
      "Epoch: 10\n",
      "[Epoch 10/20] [Batch 7/8] [Loss: 2.240716 (1.164317), Acc: 16.67% (62.42%)]Validation loss decreased (1.234240 --> 1.164317).  Saving model ...\n",
      "val Accuracy: 62.423896499238964\n",
      "Epoch: 11\n",
      "[Epoch 11/20] [Batch 7/8] [Loss: 1.981152 (1.080253), Acc: 33.33% (66.33%)]Validation loss decreased (1.164317 --> 1.080253).  Saving model ...\n",
      "val Accuracy: 66.33371385083713\n",
      "Epoch: 12\n",
      "[Epoch 12/20] [Batch 7/8] [Loss: 2.051329 (1.055109), Acc: 33.33% (67.53%)]Validation loss decreased (1.080253 --> 1.055109).  Saving model ...\n",
      "val Accuracy: 67.53234398782342\n",
      "Epoch: 13\n",
      "[Epoch 13/20] [Batch 7/8] [Loss: 2.001972 (0.979758), Acc: 50.00% (70.96%)]Validation loss decreased (1.055109 --> 0.979758).  Saving model ...\n",
      "val Accuracy: 70.9601725012684\n",
      "Epoch: 14\n",
      "[Epoch 14/20] [Batch 7/8] [Loss: 2.527301 (0.940250), Acc: 33.33% (72.54%)]Validation loss decreased (0.979758 --> 0.940250).  Saving model ...\n",
      "val Accuracy: 72.54090563165904\n",
      "Epoch: 15\n",
      "[Epoch 15/20] [Batch 7/8] [Loss: 3.585107 (0.865956), Acc: 16.67% (77.44%)]Validation loss decreased (0.940250 --> 0.865956).  Saving model ...\n",
      "val Accuracy: 77.44165398274987\n",
      "Epoch: 16\n",
      "[Epoch 16/20] [Batch 7/8] [Loss: 3.020710 (0.842196), Acc: 33.33% (78.01%)]Validation loss decreased (0.865956 --> 0.842196).  Saving model ...\n",
      "val Accuracy: 78.01243023845763\n",
      "Epoch: 17\n",
      "[Epoch 17/20] [Batch 7/8] [Loss: 1.812377 (0.760771), Acc: 16.67% (80.66%)]Validation loss decreased (0.842196 --> 0.760771).  Saving model ...\n",
      "val Accuracy: 80.66019786910198\n",
      "Epoch: 18\n",
      "[Epoch 18/20] [Batch 7/8] [Loss: 3.190394 (0.738820), Acc: 50.00% (82.71%)]Validation loss decreased (0.760771 --> 0.738820).  Saving model ...\n",
      "val Accuracy: 82.70547945205479\n",
      "Epoch: 19\n",
      "[Epoch 19/20] [Batch 7/8] [Loss: 3.681449 (0.720093), Acc: 16.67% (82.82%)]Validation loss decreased (0.738820 --> 0.720093).  Saving model ...\n",
      "val Accuracy: 82.82439117199391\n",
      "Epoch: 20\n",
      "[Epoch 20/20] [Batch 7/8] [Loss: 2.635153 (0.634875), Acc: 33.33% (86.47%)]Validation loss decreased (0.720093 --> 0.634875).  Saving model ...\n",
      "val Accuracy: 86.46943176052764\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cnn = BasicCNN(10) \n",
    "#cnn.load_state_dict(torch.load('cnn.pt')['state_dict'])\n",
    "\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), weight_decay=0.0007)\n",
    "trainCNN(cnn ,dataloaders,20,optimizer,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ncheckpoint = {'model': BasicCNN(10),\\n          'state_dict': cnn_model.state_dict(),\\n          'optimizer' : optimizer.state_dict()}\\n\\ntorch.save(checkpoint, 'cnn.pt')\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Saving a checkpoint\n",
    "torch.save(cnn.state_dict(), \"cnn.pt\")\n",
    "#torch.save(checkpoint, 'cnn.pt')\n",
    "#Loading a checkpoint\n",
    "#checkpoint = torch.load( 'cnn.pt')\n",
    "\n",
    "'''\n",
    "checkpoint = {'model': BasicCNN(10),\n",
    "          'state_dict': cnn_model.state_dict(),\n",
    "          'optimizer' : optimizer.state_dict()}\n",
    "\n",
    "torch.save(checkpoint, 'cnn.pt')\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "δ) Αρχικοποιήστε ένα μοντέλο με αυτά τα βάρη για το πρόβλημα του ερωτήματος 10 και εκπαιδεύστε το\n",
    "για λίγες εποχές (fine tuning) στο multitask dataset. Για ευκολία μπορείτε να αναφέρετε τα\n",
    "αποτελέσματα μόνο για έναν από τους 3 άξονες."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of BasicCNN(\n",
       "  (l1): Layers(\n",
       "    (conv): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (tanh): Tanh()\n",
       "  )\n",
       "  (l2): Layers(\n",
       "    (conv): Conv2d(16, 8, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (bn): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (tanh): Tanh()\n",
       "  )\n",
       "  (l3): Layers(\n",
       "    (conv): Conv2d(8, 4, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (bn): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (tanh): Tanh()\n",
       "  )\n",
       "  (l4): Layers(\n",
       "    (conv): Conv2d(4, 2, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (bn): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (tanh): Tanh()\n",
       "  )\n",
       "  (net): Sequential(\n",
       "    (0): Layers(\n",
       "      (conv): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (tanh): Tanh()\n",
       "    )\n",
       "    (1): Layers(\n",
       "      (conv): Conv2d(16, 8, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (bn): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (tanh): Tanh()\n",
       "    )\n",
       "    (2): Layers(\n",
       "      (conv): Conv2d(8, 4, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (bn): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (tanh): Tanh()\n",
       "    )\n",
       "    (3): Layers(\n",
       "      (conv): Conv2d(4, 2, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (bn): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (tanh): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (fc1): Linear(in_features=1280, out_features=10, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BasicCNN(10)\n",
    "model.load_state_dict(torch.load(\"cnn.pt\"))\n",
    "model.parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Παρακάτω θα αλλάξουμε το τελευταίο layer από το να έχει 10 εξόδους , 1 ώστε να είναι regression πρόβλημα"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc1 = nn.Linear(8 * 80 * 2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of BasicCNN(\n",
       "  (l1): Layers(\n",
       "    (conv): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (tanh): Tanh()\n",
       "  )\n",
       "  (l2): Layers(\n",
       "    (conv): Conv2d(16, 8, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (bn): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (tanh): Tanh()\n",
       "  )\n",
       "  (l3): Layers(\n",
       "    (conv): Conv2d(8, 4, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (bn): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (tanh): Tanh()\n",
       "  )\n",
       "  (l4): Layers(\n",
       "    (conv): Conv2d(4, 2, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (bn): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (tanh): Tanh()\n",
       "  )\n",
       "  (net): Sequential(\n",
       "    (0): Layers(\n",
       "      (conv): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (tanh): Tanh()\n",
       "    )\n",
       "    (1): Layers(\n",
       "      (conv): Conv2d(16, 8, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (bn): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (tanh): Tanh()\n",
       "    )\n",
       "    (2): Layers(\n",
       "      (conv): Conv2d(8, 4, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (bn): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (tanh): Tanh()\n",
       "    )\n",
       "    (3): Layers(\n",
       "      (conv): Conv2d(4, 2, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (bn): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (tanh): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (fc1): Linear(in_features=1280, out_features=1, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiDatasetCnn(Dataset): ## expanding dimensions...\n",
    "    def __init__(self, path, target ,train=True, max_length=-1, read_spec_fn=read_fused_spectrogram):\n",
    "        label_dict = {'valence': 1, 'energy': 2, 'danceability': 3}\n",
    "        self.label_idx = label_dict[target]\n",
    "        t = 'train' if train else 'test'\n",
    "        p = os.path.join(path, t)\n",
    "        self.index = os.path.join(path, \"{}_labels.txt\".format(t))\n",
    "        self.files, labels = self.get_files_labels(self.index,self.label_idx)\n",
    "        self.feats = [read_spec_fn(os.path.join(p, f)) for f in self.files]\n",
    "        self.feat_dim = self.feats[0].shape[1]\n",
    "        self.lengths = [len(i) for i in self.feats]\n",
    "            \n",
    "        self.max_length = max(self.lengths) if max_length <= 0 else max_length\n",
    "        self.zero_pad_and_stack = PaddingTransform(self.max_length)\n",
    "        \n",
    "        if isinstance(labels, (list, tuple)):\n",
    "            self.labels = np.array(labels).astype('float32')\n",
    "        #print([f.shape for f in self.feats] )\n",
    "\n",
    "    def get_files_labels(self, txt, label_idx ):\n",
    "        with open(txt, 'r') as fd:\n",
    "            lines = [l.rstrip().split('\\t') for l in fd.readlines()[1:]]\n",
    "        files, labels = [], []\n",
    "        for l in lines:\n",
    "            l = l[0].split(',')\n",
    "            _id = l[0]\n",
    "            label = l[label_idx]\n",
    "            npy_file = '{}.fused.full.npy'.format(_id)\n",
    "            files.append(npy_file)\n",
    "            labels.append(label)\n",
    "        return files, labels\n",
    "    \n",
    "    \n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        # TODO: Inspect output and comment on how the output is formatted\n",
    "        l = min(self.lengths[item], self.max_length)\n",
    "        return np.expand_dims(self.zero_pad_and_stack(self.feats[item]), 0), self.labels[item], l\n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_spec_valence = MultiDatasetCnn('/kaggle/input/patreco3-multitask-affective-music/data/multitask_dataset/','valence',train=True)\n",
    "train_loader, val_loader = torch_train_val_split(cnn_spec_valence, 32 ,32, val_size=.2, shuffle=True)\n",
    "dataloaders = {'train':train_loader,'val':val_loader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "[Epoch 1/20] [Batch 6/7] [Loss: 0.158733 (0.161031), Acc: 0.00% (0.00%)]Validation loss decreased (inf --> 0.161031).  Saving model ...\n",
      "val Accuracy: 0.0\n",
      "Epoch: 2\n",
      "[Epoch 2/20] [Batch 6/7] [Loss: 0.068035 (0.088740), Acc: 0.00% (0.00%)]Validation loss decreased (0.161031 --> 0.088740).  Saving model ...\n",
      "val Accuracy: 0.0\n",
      "Epoch: 3\n",
      "[Epoch 3/20] [Batch 6/7] [Loss: 0.121723 (0.062006), Acc: 0.00% (0.00%)]Validation loss decreased (0.088740 --> 0.062006).  Saving model ...\n",
      "val Accuracy: 0.0\n",
      "Epoch: 4\n",
      "[Epoch 4/20] [Batch 6/7] [Loss: 0.093005 (0.065227), Acc: 0.00% (0.00%)]EarlyStopping counter: 1 out of 4\n",
      "val Accuracy: 0.0\n",
      "Epoch: 5\n",
      "[Epoch 5/20] [Batch 6/7] [Loss: 0.090836 (0.054755), Acc: 0.00% (0.00%)]Validation loss decreased (0.062006 --> 0.054755).  Saving model ...\n",
      "val Accuracy: 0.0\n",
      "Epoch: 6\n",
      "[Epoch 6/20] [Batch 6/7] [Loss: 0.079308 (0.046847), Acc: 0.00% (0.00%)]Validation loss decreased (0.054755 --> 0.046847).  Saving model ...\n",
      "val Accuracy: 0.0\n",
      "Epoch: 7\n",
      "[Epoch 7/20] [Batch 6/7] [Loss: 0.113888 (0.044984), Acc: 0.00% (0.00%)]Validation loss decreased (0.046847 --> 0.044984).  Saving model ...\n",
      "val Accuracy: 0.0\n",
      "Epoch: 8\n",
      "[Epoch 8/20] [Batch 6/7] [Loss: 0.106078 (0.061535), Acc: 0.00% (0.00%)]EarlyStopping counter: 1 out of 4\n",
      "val Accuracy: 0.0\n",
      "Epoch: 9\n",
      "[Epoch 9/20] [Batch 6/7] [Loss: 0.096997 (0.040952), Acc: 0.00% (0.00%)]Validation loss decreased (0.044984 --> 0.040952).  Saving model ...\n",
      "val Accuracy: 0.0\n",
      "Epoch: 10\n",
      "[Epoch 10/20] [Batch 6/7] [Loss: 0.085539 (0.035975), Acc: 0.00% (0.00%)]Validation loss decreased (0.040952 --> 0.035975).  Saving model ...\n",
      "val Accuracy: 0.0\n",
      "Epoch: 11\n",
      "[Epoch 11/20] [Batch 6/7] [Loss: 0.092094 (0.033927), Acc: 0.00% (0.00%)]Validation loss decreased (0.035975 --> 0.033927).  Saving model ...\n",
      "val Accuracy: 0.0\n",
      "Epoch: 12\n",
      "[Epoch 12/20] [Batch 6/7] [Loss: 0.104461 (0.030610), Acc: 0.00% (0.00%)]Validation loss decreased (0.033927 --> 0.030610).  Saving model ...\n",
      "val Accuracy: 0.0\n",
      "Epoch: 13\n",
      "[Epoch 13/20] [Batch 6/7] [Loss: 0.124704 (0.026160), Acc: 0.00% (0.00%)]Validation loss decreased (0.030610 --> 0.026160).  Saving model ...\n",
      "val Accuracy: 0.0\n",
      "Epoch: 14\n",
      "[Epoch 14/20] [Batch 6/7] [Loss: 0.061093 (0.026352), Acc: 0.00% (0.00%)]EarlyStopping counter: 1 out of 4\n",
      "val Accuracy: 0.0\n",
      "Epoch: 15\n",
      "[Epoch 15/20] [Batch 6/7] [Loss: 0.099104 (0.025221), Acc: 0.00% (0.00%)]Validation loss decreased (0.026160 --> 0.025221).  Saving model ...\n",
      "val Accuracy: 0.0\n",
      "Epoch: 16\n",
      "[Epoch 16/20] [Batch 6/7] [Loss: 0.077701 (0.027002), Acc: 0.00% (0.00%)]EarlyStopping counter: 1 out of 4\n",
      "val Accuracy: 0.0\n",
      "Epoch: 17\n",
      "[Epoch 17/20] [Batch 6/7] [Loss: 0.090272 (0.028209), Acc: 0.00% (0.00%)]EarlyStopping counter: 2 out of 4\n",
      "val Accuracy: 0.0\n",
      "Epoch: 18\n",
      "[Epoch 18/20] [Batch 6/7] [Loss: 0.094330 (0.030167), Acc: 0.00% (0.00%)]EarlyStopping counter: 3 out of 4\n",
      "val Accuracy: 0.0\n",
      "Epoch: 19\n",
      "[Epoch 19/20] [Batch 6/7] [Loss: 0.099776 (0.028849), Acc: 0.00% (0.00%)]EarlyStopping counter: 4 out of 4\n",
      "Early stopping\n",
      "val Accuracy: 0.0\n",
      "val Accuracy: 0.0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (20,) and (19,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-ab3e24928a65>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0moptimizerCNN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrainCNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mdataloaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizerCNN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# true for mseloss criterion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-6a12083d84c6>\u001b[0m in \u001b[0;36mtrainCNN\u001b[0;34m(model, dataloaders, num_epochs, optimizer, patience, crit)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mepochs_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'red'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'blue'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'training-red'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'validation-blue'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'upper left'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2809\u001b[0m     return gca().plot(\n\u001b[1;32m   2810\u001b[0m         *args, scalex=scalex, scaley=scaley, **({\"data\": data} if data\n\u001b[0;32m-> 2811\u001b[0;31m         is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1808\u001b[0m                         \u001b[0;34m\"the Matplotlib list!)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1810\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1812\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_alias_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1611\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1612\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m             \u001b[0mlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_grab_next_args\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    391\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xy_from_xy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'plot'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_xy_from_xy\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m             raise ValueError(\"x and y must have same first dimension, but \"\n\u001b[0;32m--> 231\u001b[0;31m                              \"have shapes {} and {}\".format(x.shape, y.shape))\n\u001b[0m\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             raise ValueError(\"x and y can be no greater than 2-D, but have \"\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (20,) and (19,)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "optimizerCNN = torch.optim.Adam(model.parameters(), weight_decay=0.001)\n",
    "trainCNN(model ,dataloaders,20,optimizerCNN,4,True) # true for mseloss criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.026717721613951854\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SpearmanrResult(correlation=0.8186349088726046, pvalue=5.146567135881868e-272)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def CNN_REG(test_loader, model, criterion):\n",
    "    predictions, y_test, test_loss = [], [], []\n",
    "    model.eval()\n",
    "    model.to(0)\n",
    "    for i_batch, data_batched in enumerate(test_loader, 0):\n",
    "        data_batched[0], data_batched[2] = data_batched[0].to(0), data_batched[2].to(0)\n",
    "        y_pred = model(data_batched[0]).to(0)\n",
    "        preds = y_pred.data.cpu().numpy()\n",
    "        predictions += list(preds)\n",
    "        # get sorted version of y_test\n",
    "        data_batched[1] = data_batched[1].to(0)\n",
    "        y_test += list(data_batched[1].data.cpu().numpy())\n",
    "        loss = criterion(y_pred.squeeze(), data_batched[1]) \n",
    "        test_loss.append(loss.item()) \n",
    "    total_loss = np.mean(test_loss)\n",
    "    print('Test loss: {}'.format(total_loss))\n",
    "    return predictions, y_test\n",
    "\n",
    "test_loader = DataLoader(cnn_spec_valence, batch_size=32)\n",
    "criterion_regr = nn.MSELoss()\n",
    "predictions_cnn, labels_cnn = CNN_REG(test_loader, model, criterion_regr)\n",
    "spearmanr(labels_cnn, predictions_cnn) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Παρατηρούμε πως σε σχέση με τα result του ερωτήματος 8 με το CNN πετυχαίνουμε καλύτερο loss αλλά πιο μικρό spearman correlation.\n",
    "\n",
    "Παρακάτω είναι τα αποτελέσματα από το βήμα 8 για το valence με cnn.\n",
    "\n",
    "test loss: 0.04630210085047616\n",
    "SpearmanrResult(correlation=0.8333189995161571, pvalue=1.3358874111631322e-290)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

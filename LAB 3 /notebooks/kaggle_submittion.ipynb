{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import SubsetRandomSampler, DataLoader\n",
    "import re\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "# Combine similar classes and remove underrepresented classes\n",
    "class_mapping = {\n",
    "    'Rock': 'Rock',\n",
    "    'Psych-Rock': 'Rock',\n",
    "    'Indie-Rock': None,\n",
    "    'Post-Rock': 'Rock',\n",
    "    'Psych-Folk': 'Folk',\n",
    "    'Folk': 'Folk',\n",
    "    'Metal': 'Metal',\n",
    "    'Punk': 'Metal',\n",
    "    'Post-Punk': None,\n",
    "    'Trip-Hop': 'Trip-Hop',\n",
    "    'Pop': 'Pop',\n",
    "    'Electronic': 'Electronic',\n",
    "    'Hip-Hop': 'Hip-Hop',\n",
    "    'Classical': 'Classical',\n",
    "    'Blues': 'Blues',\n",
    "    'Chiptune': 'Electronic',\n",
    "    'Jazz': 'Jazz',\n",
    "    'Soundtrack': None,\n",
    "    'International': None,\n",
    "    'Old-Time': None\n",
    "}\n",
    "\n",
    "def torch_train_val_split(dataset, batch_train, batch_eval,val_size=.2, shuffle=True, seed=None):\n",
    "    # Creating data indices for training and validation splits:\n",
    "    dataset_size = len(dataset)\n",
    "    indices = list(range(dataset_size))\n",
    "    val_split = int(np.floor(val_size * dataset_size))\n",
    "    if shuffle:\n",
    "        np.random.seed(seed)\n",
    "        np.random.shuffle(indices)\n",
    "    train_indices = indices[val_split:]\n",
    "    val_indices = indices[:val_split]\n",
    "\n",
    "    # Creating PT data samplers and loaders:\n",
    "    train_sampler = SubsetRandomSampler(train_indices)\n",
    "    val_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "    train_loader = DataLoader(dataset,\n",
    "                              batch_size=batch_train,\n",
    "                              sampler=train_sampler)\n",
    "    val_loader = DataLoader(dataset,\n",
    "                            batch_size=batch_eval,\n",
    "                            sampler=val_sampler)\n",
    "    return train_loader, val_loader\n",
    "\n",
    "\n",
    "def read_fused_spectrogram(spectrogram_file):\n",
    "    spectrogram = np.load(spectrogram_file)\n",
    "    return spectrogram.T\n",
    "\n",
    "\n",
    "def read_mel_spectrogram(spectrogram_file):\n",
    "    spectrogram = np.load(spectrogram_file)[:128]\n",
    "    return spectrogram.T\n",
    "\n",
    "    \n",
    "def read_chromagram(spectrogram_file):\n",
    "    spectrogram = np.load(spectrogram_file)[128:]\n",
    "    return spectrogram.T\n",
    "\n",
    "\n",
    "class LabelTransformer(LabelEncoder):\n",
    "    def inverse(self, y):\n",
    "        try:\n",
    "            return super(LabelTransformer, self).inverse_transform(y)\n",
    "        except:\n",
    "            return super(LabelTransformer, self).inverse_transform([y])\n",
    "\n",
    "    def transform(self, y):\n",
    "        try:\n",
    "            return super(LabelTransformer, self).transform(y)\n",
    "        except:\n",
    "            return super(LabelTransformer, self).transform([y])\n",
    "\n",
    "\n",
    "\n",
    "class PaddingTransform(object):\n",
    "    def __init__(self, max_length, padding_value=0):\n",
    "        self.max_length = max_length\n",
    "        self.padding_value = padding_value\n",
    "    #https://stackoverflow.com/questions/9663562/what-is-the-difference-between-init-and-call\n",
    "    def __call__(self, s):\n",
    "        if len(s) == self.max_length:\n",
    "            return s\n",
    "\n",
    "        if len(s) > self.max_length:\n",
    "            return s[:self.max_length]\n",
    "\n",
    "        if len(s) < self.max_length:\n",
    "            #https://www.geeksforgeeks.org/copy-python-deep-copy-shallow-copy/\n",
    "            s1 = copy.deepcopy(s)\n",
    "            pad = np.zeros((self.max_length - s.shape[0], s.shape[1]), dtype=np.float32)\n",
    "            s1 = np.vstack((s1, pad))\n",
    "            return s1\n",
    "        \n",
    "class MultiDatasetCnn(Dataset): ## expanding dimensions...\n",
    "    def __init__(self, path ,train=True, max_length=-1, read_spec_fn=read_fused_spectrogram):\n",
    "        t = 'train' if train else 'test'\n",
    "        p = os.path.join(path, t)\n",
    "        self.index = os.path.join(path, \"{}_labels.txt\".format(t))\n",
    "        self.files, labels = self.get_files_labels(self.index)\n",
    "        self.feats = [read_spec_fn(os.path.join(p, f)) for f in self.files]\n",
    "        self.feat_dim = self.feats[0].shape[1]\n",
    "        self.lengths = [len(i) for i in self.feats]\n",
    "        self.max_length = max(self.lengths) if max_length <= 0 else max_length\n",
    "        self.zero_pad_and_stack = PaddingTransform(self.max_length)\n",
    "        \n",
    "        if isinstance(labels, (list, tuple)):\n",
    "            self.labels = np.array(labels).astype('float32')\n",
    "        #print([f.shape for f in self.feats] )\n",
    "\n",
    "    def get_files_labels(self, txt):\n",
    "        with open(txt, 'r') as fd:\n",
    "            lines = [l.rstrip().split('\\t') for l in fd.readlines()[1:]]\n",
    "        files, labels = [], []\n",
    "        for l in lines:\n",
    "            l = l[0].split(',')\n",
    "            _id = l[0]\n",
    "            label = l[1:] # load all labels, valence,energy,danceability\n",
    "            npy_file = '{}.fused.full.npy'.format(_id)\n",
    "            files.append(npy_file)\n",
    "            labels.append(label)\n",
    "        return files, labels\n",
    "    \n",
    "    \n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        l = min(self.lengths[item], self.max_length)\n",
    "        return np.expand_dims(self.zero_pad_and_stack(self.feats[item]), 0), self.labels[item], l\n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7, verbose=False):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score:\n",
    "            self.counter += 1\n",
    "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), 'checkpoint.pt')\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = MultiDatasetCnn('/kaggle/input/patreco3-multitask-affective-music/data/multitask_dataset/', train=True, max_length=-1) \n",
    "train_loader, val_loader = torch_train_val_split(data, 32 ,32, val_size=.2, shuffle=True)\n",
    "test_loader = DataLoader(data, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "class Layers(nn.Module):\n",
    "    def __init__(self,in_c,out_c):\n",
    "        super(Layers,self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels=in_c,kernel_size=5,out_channels=out_c,stride=1,padding=2)\n",
    "        self.bn = nn.BatchNorm2d(num_features=out_c)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self,x):\n",
    "        output = self.conv(x.float())\n",
    "        output = self.bn(output)\n",
    "        output = self.tanh(output)\n",
    "        output = self.pool(output)\n",
    "        return output\n",
    "\n",
    "class BasicCNN(nn.Module):\n",
    "    def __init__(self, classes):\n",
    "        super(BasicCNN, self).__init__()\n",
    "        self.classes = classes\n",
    "        self.l1 = Layers(in_c=1, out_c=16)\n",
    "        self.l2 = Layers(in_c=16, out_c=8)\n",
    "        self.l3 = Layers(in_c=8, out_c=4)\n",
    "        self.l4 = Layers(in_c=4, out_c=2)\n",
    "        self.net = nn.Sequential(self.l1, self.l2, self.l3, self.l4)\n",
    "        self.fc1 = nn.Linear(8 * 80 * 2, self.classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        output = self.net(x)\n",
    "        output = output.view(-1, 8 * 80 * 2)\n",
    "        output = self.fc1(output)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BasicCNN(3)\n",
    "optimizer = torch.optim.Adam(model.parameters(), weight_decay=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {'train':train_loader,'val':val_loader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainCNN(model,dataloaders,num_epochs,optimizer,patience,crit=False):\n",
    "    Flag=False\n",
    "    # for loss\n",
    "    val_loss = []\n",
    "    train_loss = []\n",
    "    phase1 = dataloaders.keys()\n",
    "    criterion = nn.MSELoss()\n",
    "    train_loader = dataloaders['train']\n",
    "    if(torch.cuda.is_available()):\n",
    "        device = 0\n",
    "        model.to(device)\n",
    "    else:\n",
    "        device = 'cpu'\n",
    "        model.to(device)\n",
    "    if(patience!=None):\n",
    "        earlystop = EarlyStopping(patience = patience,verbose = True)\n",
    "    for epoch in range(num_epochs):\n",
    "        counter = epoch # keeping this variable for plot function after for loop\n",
    "        if Flag == True:\n",
    "            break\n",
    "        print('Epoch:',epoch + 1)\n",
    "        epoch_metrics = {\"loss\": [], \"acc\": []}\n",
    "        for phase in phase1:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "            for  batch_idx, data in enumerate(dataloaders[phase]):\n",
    "                optimizer.zero_grad()\n",
    "                output = model(data[0].to(device)).to(device)\n",
    "                loss_valence= criterion(output.squeeze()[:,0], data[1][:,0].to(device))\n",
    "                loss_energy = criterion(output.squeeze()[:,1], data[1][:,1].to(device))\n",
    "                loss_dance  = criterion(output.squeeze()[:,2], data[1][:,2].to(device))\n",
    "                \n",
    "                sum_losses = torch.sum(torch.stack([loss_valence,loss_energy,loss_dance]))\n",
    "                epoch_metrics[\"loss\"].append(sum_losses.item())\n",
    "                sys.stdout.write(\n",
    "                \"\\r[Epoch %d/%d] [Batch %d/%d] [Loss: %f (%f)]\"\n",
    "                % (\n",
    "                    epoch + 1,\n",
    "                    num_epochs,\n",
    "                    batch_idx,\n",
    "                    len(dataloaders[phase]),\n",
    "                    sum_losses.item(),\n",
    "                    np.mean(epoch_metrics[\"loss\"])\n",
    "                    )\n",
    "                )\n",
    "\n",
    "                if(phase =='train'):\n",
    "                    sum_losses.backward()\n",
    "                    optimizer.step()\n",
    "            \n",
    "            epoch_loss = np.mean(epoch_metrics[\"loss\"])\n",
    "            \n",
    "            if phase == 'train':\n",
    "                train_loss.append(epoch_loss)\n",
    "            else: \n",
    "                val_loss.append(epoch_loss)\n",
    "            if(phase == 'val' and patience !=None):\n",
    "                earlystop(epoch_loss,model)\n",
    "                if(earlystop.early_stop):\n",
    "                    print(\"Early stopping\")\n",
    "                    model.load_state_dict(torch.load('./checkpoint.pt'))\n",
    "                    #break\n",
    "                    Flag = True\n",
    "    if counter == num_epochs -1:\n",
    "        epochs_axis = np.arange(num_epochs)\n",
    "    else:\n",
    "        epochs_axis = np.arange(counter)\n",
    "    plt.plot(epochs_axis, train_loss,color='red')\n",
    "    plt.plot(epochs_axis, val_loss,color='blue')\n",
    "    plt.legend(['training-red', 'validation-blue'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "[Epoch 1/20] [Batch 6/7] [Loss: 0.324305 (0.398683)]Validation loss decreased (inf --> 0.398683).  Saving model ...\n",
      "Epoch: 2\n",
      "[Epoch 2/20] [Batch 6/7] [Loss: 0.212395 (0.168522)]Validation loss decreased (0.398683 --> 0.168522).  Saving model ...\n",
      "Epoch: 3\n",
      "[Epoch 3/20] [Batch 6/7] [Loss: 0.191258 (0.140427)]Validation loss decreased (0.168522 --> 0.140427).  Saving model ...\n",
      "Epoch: 4\n",
      "[Epoch 4/20] [Batch 6/7] [Loss: 0.149378 (0.137646)]Validation loss decreased (0.140427 --> 0.137646).  Saving model ...\n",
      "Epoch: 5\n",
      "[Epoch 5/20] [Batch 6/7] [Loss: 0.208894 (0.114255)]Validation loss decreased (0.137646 --> 0.114255).  Saving model ...\n",
      "Epoch: 6\n",
      "[Epoch 6/20] [Batch 6/7] [Loss: 0.162571 (0.123257)]EarlyStopping counter: 1 out of 3\n",
      "Epoch: 7\n",
      "[Epoch 7/20] [Batch 6/7] [Loss: 0.162289 (0.098725)]Validation loss decreased (0.114255 --> 0.098725).  Saving model ...\n",
      "Epoch: 8\n",
      "[Epoch 8/20] [Batch 6/7] [Loss: 0.110890 (0.095304)]Validation loss decreased (0.098725 --> 0.095304).  Saving model ...\n",
      "Epoch: 9\n",
      "[Epoch 9/20] [Batch 6/7] [Loss: 0.131902 (0.090247)]Validation loss decreased (0.095304 --> 0.090247).  Saving model ...\n",
      "Epoch: 10\n",
      "[Epoch 10/20] [Batch 6/7] [Loss: 0.160651 (0.096418)]EarlyStopping counter: 1 out of 3\n",
      "Epoch: 11\n",
      "[Epoch 11/20] [Batch 6/7] [Loss: 0.166088 (0.106546)]EarlyStopping counter: 2 out of 3\n",
      "Epoch: 12\n",
      "[Epoch 12/20] [Batch 6/7] [Loss: 0.145913 (0.089606)]Validation loss decreased (0.090247 --> 0.089606).  Saving model ...\n",
      "Epoch: 13\n",
      "[Epoch 13/20] [Batch 6/7] [Loss: 0.134091 (0.075178)]Validation loss decreased (0.089606 --> 0.075178).  Saving model ...\n",
      "Epoch: 14\n",
      "[Epoch 14/20] [Batch 6/7] [Loss: 0.157156 (0.080799)]EarlyStopping counter: 1 out of 3\n",
      "Epoch: 15\n",
      "[Epoch 15/20] [Batch 6/7] [Loss: 0.110018 (0.071101)]Validation loss decreased (0.075178 --> 0.071101).  Saving model ...\n",
      "Epoch: 16\n",
      "[Epoch 16/20] [Batch 6/7] [Loss: 0.177386 (0.065332)]Validation loss decreased (0.071101 --> 0.065332).  Saving model ...\n",
      "Epoch: 17\n",
      "[Epoch 17/20] [Batch 6/7] [Loss: 0.133398 (0.058237)]Validation loss decreased (0.065332 --> 0.058237).  Saving model ...\n",
      "Epoch: 18\n",
      "[Epoch 18/20] [Batch 6/7] [Loss: 0.136486 (0.060901)]EarlyStopping counter: 1 out of 3\n",
      "Epoch: 19\n",
      "[Epoch 19/20] [Batch 6/7] [Loss: 0.175908 (0.063057)]EarlyStopping counter: 2 out of 3\n",
      "Epoch: 20\n",
      "[Epoch 20/20] [Batch 6/7] [Loss: 0.134144 (0.065193)]EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainCNN(model,dataloaders,20,optimizer,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict on Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_REG(test_loader, model, criterion,device=0):\n",
    "    \n",
    "    test_loss = []\n",
    "    predictions = []\n",
    "    ytest  = []\n",
    "    predictions_dance, y_test_dance = [], []\n",
    "    model.eval()\n",
    "    model.to(0)\n",
    "    for i_batch, data_batched in enumerate(test_loader, 0):\n",
    "        data_batched[0], data_batched[2] = data_batched[0].to(0), data_batched[2].to(0)\n",
    "        output = model(data_batched[0]).to(0)\n",
    "        \n",
    "        predictions_val , predictions_en , predictions_dance = output.squeeze()[:,0],output.squeeze()[:,1],output.squeeze()[:,2]\n",
    "        y_test_val , y_test_en , y_test_dance =  data_batched[1][:,0].to(device),data_batched[1][:,1].to(device),data_batched[1][:,2].to(device)\n",
    "        \n",
    "        loss_valence= criterion(predictions_val,   y_test_val)\n",
    "        loss_energy = criterion(predictions_en,    y_test_en)\n",
    "        loss_dance  = criterion(predictions_dance, y_test_dance)\n",
    "        \n",
    "        loss = torch.sum(torch.stack([loss_valence,loss_energy,loss_dance]))\n",
    "        test_loss.append(loss.item()) \n",
    "        \n",
    "        preds1 = predictions_val.data.cpu().numpy()\n",
    "        preds2 = predictions_en.data.cpu().numpy()\n",
    "        preds3 = predictions_dance.data.cpu().numpy()\n",
    "        \n",
    "        predictions += list(preds1)\n",
    "        predictions += list(preds2)\n",
    "        predictions += list(preds3)\n",
    "    \n",
    "        ytest += list(y_test_val.data.cpu().numpy())  \n",
    "        ytest += list(y_test_en.data.cpu().numpy()) \n",
    "        ytest += list(y_test_dance.data.cpu().numpy()) \n",
    "        \n",
    "    total_loss = np.mean(test_loss)\n",
    "    print('Test loss: {}'.format(total_loss))\n",
    "    return predictions, ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.05702364962134096\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SpearmanrResult(correlation=0.826440821303077, pvalue=0.0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion_regr = nn.MSELoss()\n",
    "predictions_cnn, labels_cnn = CNN_REG(test_loader, model, criterion_regr)\n",
    "spearmanr(labels_cnn, predictions_cnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Παρατηρούμε πως πετύχαμε loss περίπου 0.1 με καλό correlation το οποίο είναι στατιστικά σημαντικό."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Υποβολή στο kaggle. Αλλάζουμε τη συνάρτηση με το dataset ώστε να διαβάσουμε τα δεδομένα στο φάκελο test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiDatasetCnn2(Dataset): ## expanding dimensions...\n",
    "    def __init__(self,  max_length=-1, read_spec_fn=read_fused_spectrogram):\n",
    "        #t = 'train' if train else 'test'\n",
    "        path = '/kaggle/input/patreco3-multitask-affective-music/data/multitask_dataset/test'\n",
    "        p = os.listdir('/kaggle/input/patreco3-multitask-affective-music/data/multitask_dataset/test')\n",
    "        #self.index = os.path.join(path, \"{}_labels.txt\".format(t))\n",
    "        #self.files, labels = self.get_files_labels(self.index)\n",
    "        files = []\n",
    "        for i in p:\n",
    "            files.append(os.path.join(path,i))\n",
    "        self.feats = [read_spec_fn(f) for f in files]\n",
    "        self.feat_dim = self.feats[0].shape[1]\n",
    "        self.lengths = [len(i) for i in self.feats]\n",
    "        self.max_length = max(self.lengths) if max_length <= 0 else max_length\n",
    "        self.zero_pad_and_stack = PaddingTransform(self.max_length)\n",
    "        \n",
    "        if isinstance(p, (list, tuple)):\n",
    "            self.p = np.array(p)\n",
    "        #print([f.shape for f in self.feats] )\n",
    "\n",
    "    def get_files_labels(self, txt):\n",
    "        with open(txt, 'r') as fd:\n",
    "            lines = [l.rstrip().split('\\t') for l in fd.readlines()[1:]]\n",
    "        files, labels = [], []\n",
    "        for l in lines:\n",
    "            l = l[0].split(',')\n",
    "            _id = l[0]\n",
    "            label = l[1:] # load all labels, valence,energy,danceability\n",
    "            npy_file = '{}.fused.full.npy'.format(_id)\n",
    "            files.append(npy_file)\n",
    "            labels.append(label)\n",
    "        return files, labels\n",
    "    \n",
    "    \n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        l = min(self.lengths[item], self.max_length)\n",
    "        return np.expand_dims(self.zero_pad_and_stack(self.feats[item]), 0), self.p[item] \n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.feats)\n",
    "\n",
    "\n",
    "\n",
    "data = MultiDatasetCnn2(max_length=-1) \n",
    "test_loader = DataLoader(data, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.path.join('/kaggle/input/patreco3-multitask-affective-music/data/multitask_dataset/test','fo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'7659.fused.full.npy'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#os.listdir('/kaggle/input/patreco3-multitask-affective-music/data/multitask_dataset/test')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/kaggle/input/patreco3-multitask-affective-music/data/multitask_dataset/test/7659.fused.full.npy'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#os.path.join('/kaggle/input/patreco3-multitask-affective-music/data/multitask_dataset/test','7659.fused.full.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_REG(test_loader, model, criterion,device=0):\n",
    "    \n",
    "    #test_loss = []\n",
    "    #predictions = []\n",
    "    #ytest  = []\n",
    "    pred_id,predictions_valence, predictions_energy,predictions_danceability = [], [], [] , []\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    for i_batch, data_batched in enumerate(test_loader, 0):\n",
    "        data_batched[0] = data_batched[0].to(device)\n",
    "        #print(data_batched[1])\n",
    "        data_batched[1] =  data_batched[1]#.to(device)\n",
    "        output = model(data_batched[0]).to(device)\n",
    "        \n",
    "        predictions_val , predictions_en , predictions_dance = output.squeeze()[:,0],output.squeeze()[:,1],output.squeeze()[:,2]\n",
    "        #y_test_val , y_test_en , y_test_dance =  data_batched[1][:,0].to(device),data_batched[1][:,1].to(device),data_batched[1][:,2].to(device)\n",
    "        predictions_valence += list(predictions_val.data.cpu().numpy())\n",
    "        predictions_energy += list(predictions_en.data.cpu().numpy())\n",
    "        predictions_danceability += list(predictions_dance.data.cpu().numpy())\n",
    "        pred_id += list(data_batched[1])\n",
    "        \n",
    "    #total_loss = np.mean(test_loss)\n",
    "    #print('Test loss: {}'.format(total_loss))\n",
    "    return pred_id,predictions_valence,predictions_energy, predictions_danceability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid,val,en,dance = CNN_REG(test_loader, model, criterion_regr,device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id.fused.full.npy</th>\n",
       "      <th>valence</th>\n",
       "      <th>energy</th>\n",
       "      <th>dance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7659.fused.full.npy</td>\n",
       "      <td>0.780193</td>\n",
       "      <td>0.736285</td>\n",
       "      <td>0.754877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1704.fused.full.npy</td>\n",
       "      <td>0.637906</td>\n",
       "      <td>0.499492</td>\n",
       "      <td>0.610718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9250.fused.full.npy</td>\n",
       "      <td>0.631738</td>\n",
       "      <td>0.898681</td>\n",
       "      <td>0.421798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1652.fused.full.npy</td>\n",
       "      <td>0.636361</td>\n",
       "      <td>0.922732</td>\n",
       "      <td>0.609474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2514.fused.full.npy</td>\n",
       "      <td>0.478625</td>\n",
       "      <td>0.514503</td>\n",
       "      <td>0.709588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Id.fused.full.npy   valence    energy     dance\n",
       "0  7659.fused.full.npy  0.780193  0.736285  0.754877\n",
       "1  1704.fused.full.npy  0.637906  0.499492  0.610718\n",
       "2  9250.fused.full.npy  0.631738  0.898681  0.421798\n",
       "3  1652.fused.full.npy  0.636361  0.922732  0.609474\n",
       "4  2514.fused.full.npy  0.478625  0.514503  0.709588"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solution = pd.DataFrame({'Id.fused.full.npy':pid,'valence':val,'energy':en,'danceability':dance})\n",
    "solution.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved file: solution.txt\n"
     ]
    }
   ],
   "source": [
    "filename = 'solution.txt'\n",
    "solution.to_csv(filename,index=False)\n",
    "print('Saved file: ' + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

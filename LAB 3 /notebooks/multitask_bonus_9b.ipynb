{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ΔΗΜΗΤΡΗΣ ΖΕΡΚΕΛΙΔΗΣ ~ 03400049\n",
    "### ΜΑΡΙΑ ΚΑΙΚΤΖΟΓΛΟΥ ~ 03400052\n",
    "\n",
    "#### ΕΡΩΤΗΜΑ 9β ~ Multitasking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Περιγραφή προβλήματος και αποτελέσματα:\n",
    "    \n",
    "    Στο συγκεκριμένο πρόβλημα, το μοντέλο που διαλέξαμε είναι το CNN, καθώς όπως είχαμε δει είχε πολύ καλύτερα αποτελέσματα από του lstm. Επίσης το εκπαιδεύσαμε με 3 εξόδους μια για κάθε συναίσθημα , energy , valence , danceability. Εν συνεχεία, διαλέξαμε για συνάρτηση κόστους την MSE λόγω του ότι έχουμε πρόβλημα παλινδρόμησης.\n",
    "    \n",
    "    Στο μοντέλο μας κάνουμε χρήση multitasking - Hard Sharing Parameter, δηλαδή έχουμε κοινά layers αλλά μετά στο τέλος ξεχωριστά για να διακρίνουμε τα 3 συναισθήματα.\n",
    "    \n",
    "    Στο training προσθέτω το loss για το κάθε task (1 για valence , 1 για energy , 1 για danceability) και κάνουμε back propagation και step με αυτό το άθροισμα. Επομένως, με αυτόν τον τρόπο συνδυάζοντας τα loss το μοντέλο μας δεν κάνει overfit καθώς η συνάρτηση κόστους αποτελείται από παραπάνω μεταβλητές που την επηρεάζουν με αποτέλεσμα να τιμωρείται ένα πολύπλοκο νευρωνικό δίκτυο.\n",
    "    \n",
    "    Το ΜΤL γενικά βελτιώνει τη γενίκευση, με τη χρήση σχετικών tasks, αφού προσπαθεί το μοντέλο να εξηγήσει παραπάνω από μια υπόθεση.\n",
    "    \n",
    "    Αποτελέσματα δικτύου:\n",
    "    \n",
    "        0.1 loss με spearman correlation 0.55 με p value πολύ μικρό επομένως είναι στατιστικά σημαντικό\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Παρακάτω ακολουθεί ο κώδικας για το Multitasking με χρήση συνελικτικών δικτύων."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import SubsetRandomSampler, DataLoader\n",
    "import re\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "# Combine similar classes and remove underrepresented classes\n",
    "class_mapping = {\n",
    "    'Rock': 'Rock',\n",
    "    'Psych-Rock': 'Rock',\n",
    "    'Indie-Rock': None,\n",
    "    'Post-Rock': 'Rock',\n",
    "    'Psych-Folk': 'Folk',\n",
    "    'Folk': 'Folk',\n",
    "    'Metal': 'Metal',\n",
    "    'Punk': 'Metal',\n",
    "    'Post-Punk': None,\n",
    "    'Trip-Hop': 'Trip-Hop',\n",
    "    'Pop': 'Pop',\n",
    "    'Electronic': 'Electronic',\n",
    "    'Hip-Hop': 'Hip-Hop',\n",
    "    'Classical': 'Classical',\n",
    "    'Blues': 'Blues',\n",
    "    'Chiptune': 'Electronic',\n",
    "    'Jazz': 'Jazz',\n",
    "    'Soundtrack': None,\n",
    "    'International': None,\n",
    "    'Old-Time': None\n",
    "}\n",
    "\n",
    "def torch_train_val_split(dataset, batch_train, batch_eval,val_size=.2, shuffle=True, seed=None):\n",
    "    # Creating data indices for training and validation splits:\n",
    "    dataset_size = len(dataset)\n",
    "    indices = list(range(dataset_size))\n",
    "    val_split = int(np.floor(val_size * dataset_size))\n",
    "    if shuffle:\n",
    "        np.random.seed(seed)\n",
    "        np.random.shuffle(indices)\n",
    "    train_indices = indices[val_split:]\n",
    "    val_indices = indices[:val_split]\n",
    "\n",
    "    # Creating PT data samplers and loaders:\n",
    "    train_sampler = SubsetRandomSampler(train_indices)\n",
    "    val_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "    train_loader = DataLoader(dataset,\n",
    "                              batch_size=batch_train,\n",
    "                              sampler=train_sampler)\n",
    "    val_loader = DataLoader(dataset,\n",
    "                            batch_size=batch_eval,\n",
    "                            sampler=val_sampler)\n",
    "    return train_loader, val_loader\n",
    "\n",
    "\n",
    "def read_fused_spectrogram(spectrogram_file):\n",
    "    spectrogram = np.load(spectrogram_file)\n",
    "    return spectrogram.T\n",
    "\n",
    "\n",
    "def read_mel_spectrogram(spectrogram_file):\n",
    "    spectrogram = np.load(spectrogram_file)[:128]\n",
    "    return spectrogram.T\n",
    "\n",
    "    \n",
    "def read_chromagram(spectrogram_file):\n",
    "    spectrogram = np.load(spectrogram_file)[128:]\n",
    "    return spectrogram.T\n",
    "\n",
    "\n",
    "class LabelTransformer(LabelEncoder):\n",
    "    def inverse(self, y):\n",
    "        try:\n",
    "            return super(LabelTransformer, self).inverse_transform(y)\n",
    "        except:\n",
    "            return super(LabelTransformer, self).inverse_transform([y])\n",
    "\n",
    "    def transform(self, y):\n",
    "        try:\n",
    "            return super(LabelTransformer, self).transform(y)\n",
    "        except:\n",
    "            return super(LabelTransformer, self).transform([y])\n",
    "\n",
    "\n",
    "\n",
    "class PaddingTransform(object):\n",
    "    def __init__(self, max_length, padding_value=0):\n",
    "        self.max_length = max_length\n",
    "        self.padding_value = padding_value\n",
    "    #https://stackoverflow.com/questions/9663562/what-is-the-difference-between-init-and-call\n",
    "    def __call__(self, s):\n",
    "        if len(s) == self.max_length:\n",
    "            return s\n",
    "\n",
    "        if len(s) > self.max_length:\n",
    "            return s[:self.max_length]\n",
    "\n",
    "        if len(s) < self.max_length:\n",
    "            #https://www.geeksforgeeks.org/copy-python-deep-copy-shallow-copy/\n",
    "            s1 = copy.deepcopy(s)\n",
    "            pad = np.zeros((self.max_length - s.shape[0], s.shape[1]), dtype=np.float32)\n",
    "            s1 = np.vstack((s1, pad))\n",
    "            return s1\n",
    "        \n",
    "class MultiDatasetCnn(Dataset): ## expanding dimensions...\n",
    "    def __init__(self, path ,train=True, max_length=-1, read_spec_fn=read_fused_spectrogram):\n",
    "        t = 'train' if train else 'test'\n",
    "        p = os.path.join(path, t)\n",
    "        self.index = os.path.join(path, \"{}_labels.txt\".format(t))\n",
    "        self.files, labels = self.get_files_labels(self.index)\n",
    "        self.feats = [read_spec_fn(os.path.join(p, f)) for f in self.files]\n",
    "        self.feat_dim = self.feats[0].shape[1]\n",
    "        self.lengths = [len(i) for i in self.feats]\n",
    "        self.max_length = max(self.lengths) if max_length <= 0 else max_length\n",
    "        self.zero_pad_and_stack = PaddingTransform(self.max_length)\n",
    "        \n",
    "        if isinstance(labels, (list, tuple)):\n",
    "            self.labels = np.array(labels).astype('float32')\n",
    "        #print([f.shape for f in self.feats] )\n",
    "\n",
    "    def get_files_labels(self, txt):\n",
    "        with open(txt, 'r') as fd:\n",
    "            lines = [l.rstrip().split('\\t') for l in fd.readlines()[1:]]\n",
    "        files, labels = [], []\n",
    "        for l in lines:\n",
    "            l = l[0].split(',')\n",
    "            _id = l[0]\n",
    "            label = l[1:] # load all labels, valence,energy,danceability\n",
    "            npy_file = '{}.fused.full.npy'.format(_id)\n",
    "            files.append(npy_file)\n",
    "            labels.append(label)\n",
    "        return files, labels\n",
    "    \n",
    "    \n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        l = min(self.lengths[item], self.max_length)\n",
    "        return np.expand_dims(self.zero_pad_and_stack(self.feats[item]), 0), self.labels[item], l\n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7, verbose=False):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score:\n",
    "            self.counter += 1\n",
    "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), 'checkpoint.pt')\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = MultiDatasetCnn('/kaggle/input/patreco3-multitask-affective-music/data/multitask_dataset/', train=True, max_length=-1) \n",
    "train_loader, val_loader = torch_train_val_split(data, 32 ,32, val_size=.2, shuffle=True)\n",
    "test_loader = DataLoader(data, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "class Layers(nn.Module):\n",
    "    def __init__(self,in_c,out_c):\n",
    "        super(Layers,self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels=in_c,kernel_size=5,out_channels=out_c,stride=1,padding=2)\n",
    "        self.bn = nn.BatchNorm2d(num_features=out_c)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self,x):\n",
    "        output = self.conv(x.float())\n",
    "        output = self.bn(output)\n",
    "        output = self.tanh(output)\n",
    "        output = self.pool(output)\n",
    "        return output\n",
    "\n",
    "class BasicCNN(nn.Module):\n",
    "    def __init__(self, classes):\n",
    "        super(BasicCNN, self).__init__()\n",
    "        self.classes = classes\n",
    "        self.l1 = Layers(in_c=1, out_c=16)\n",
    "        self.l2 = Layers(in_c=16, out_c=8)\n",
    "        self.l3 = Layers(in_c=8, out_c=4)\n",
    "        self.l4 = Layers(in_c=4, out_c=2)\n",
    "        self.net = nn.Sequential(self.l1, self.l2, self.l3, self.l4)\n",
    "        self.fc1 = nn.Linear(8 * 80 * 2, self.classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        output = self.net(x)\n",
    "        output = output.view(-1, 8 * 80 * 2)\n",
    "        output = self.fc1(output)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BasicCNN(3)\n",
    "optimizer = torch.optim.Adam(model.parameters(), weight_decay=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {'train':train_loader,'val':val_loader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainCNN(model,dataloaders,num_epochs,optimizer,patience,crit=False):\n",
    "    Flag=False\n",
    "    # for loss\n",
    "    val_loss = []\n",
    "    train_loss = []\n",
    "    phase1 = dataloaders.keys()\n",
    "    criterion = nn.MSELoss()\n",
    "    train_loader = dataloaders['train']\n",
    "    if(torch.cuda.is_available()):\n",
    "        device = 0\n",
    "        model.to(device)\n",
    "    else:\n",
    "        device = 'cpu'\n",
    "        model.to(device)\n",
    "    if(patience!=None):\n",
    "        earlystop = EarlyStopping(patience = patience,verbose = True)\n",
    "    for epoch in range(num_epochs):\n",
    "        counter = epoch # keeping this variable for plot function after for loop\n",
    "        if Flag == True:\n",
    "            break\n",
    "        print('Epoch:',epoch + 1)\n",
    "        epoch_metrics = {\"loss\": [], \"acc\": []}\n",
    "        for phase in phase1:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "            for  batch_idx, data in enumerate(dataloaders[phase]):\n",
    "                optimizer.zero_grad()\n",
    "                output = model(data[0].to(device)).to(device)\n",
    "                loss_valence= criterion(output.squeeze()[:,0], data[1][:,0].to(device))\n",
    "                loss_energy = criterion(output.squeeze()[:,1], data[1][:,1].to(device))\n",
    "                loss_dance  = criterion(output.squeeze()[:,2], data[1][:,2].to(device))\n",
    "                \n",
    "                sum_losses = torch.sum(torch.stack([loss_valence,loss_energy,loss_dance]))\n",
    "                epoch_metrics[\"loss\"].append(sum_losses.item())\n",
    "                sys.stdout.write(\n",
    "                \"\\r[Epoch %d/%d] [Batch %d/%d] [Loss: %f (%f)]\"\n",
    "                % (\n",
    "                    epoch + 1,\n",
    "                    num_epochs,\n",
    "                    batch_idx,\n",
    "                    len(dataloaders[phase]),\n",
    "                    sum_losses.item(),\n",
    "                    np.mean(epoch_metrics[\"loss\"])\n",
    "                    )\n",
    "                )\n",
    "\n",
    "                if(phase =='train'):\n",
    "                    sum_losses.backward()\n",
    "                    optimizer.step()\n",
    "            \n",
    "            epoch_loss = np.mean(epoch_metrics[\"loss\"])\n",
    "            \n",
    "            if phase == 'train':\n",
    "                train_loss.append(epoch_loss)\n",
    "            else: \n",
    "                val_loss.append(epoch_loss)\n",
    "            if(phase == 'val' and patience !=None):\n",
    "                earlystop(epoch_loss,model)\n",
    "                if(earlystop.early_stop):\n",
    "                    print(\"Early stopping\")\n",
    "                    model.load_state_dict(torch.load('./checkpoint.pt'))\n",
    "                    #break\n",
    "                    Flag = True\n",
    "    if counter == num_epochs -1:\n",
    "        epochs_axis = np.arange(num_epochs)\n",
    "    else:\n",
    "        epochs_axis = np.arange(counter)\n",
    "    plt.plot(epochs_axis, train_loss,color='red')\n",
    "    plt.plot(epochs_axis, val_loss,color='blue')\n",
    "    plt.legend(['training-red', 'validation-blue'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "[Epoch 1/20] [Batch 6/7] [Loss: 0.302675 (0.325494)]Validation loss decreased (inf --> 0.325494).  Saving model ...\n",
      "Epoch: 2\n",
      "[Epoch 2/20] [Batch 6/7] [Loss: 0.214698 (0.182949)]Validation loss decreased (0.325494 --> 0.182949).  Saving model ...\n",
      "Epoch: 3\n",
      "[Epoch 3/20] [Batch 6/7] [Loss: 0.192055 (0.151100)]Validation loss decreased (0.182949 --> 0.151100).  Saving model ...\n",
      "Epoch: 4\n",
      "[Epoch 4/20] [Batch 6/7] [Loss: 0.235880 (0.141894)]Validation loss decreased (0.151100 --> 0.141894).  Saving model ...\n",
      "Epoch: 5\n",
      "[Epoch 5/20] [Batch 6/7] [Loss: 0.235602 (0.180994)]EarlyStopping counter: 1 out of 3\n",
      "Epoch: 6\n",
      "[Epoch 6/20] [Batch 6/7] [Loss: 0.293956 (0.182690)]EarlyStopping counter: 2 out of 3\n",
      "Epoch: 7\n",
      "[Epoch 7/20] [Batch 6/7] [Loss: 0.155112 (0.130110)]Validation loss decreased (0.141894 --> 0.130110).  Saving model ...\n",
      "Epoch: 8\n",
      "[Epoch 8/20] [Batch 6/7] [Loss: 0.115560 (0.108138)]Validation loss decreased (0.130110 --> 0.108138).  Saving model ...\n",
      "Epoch: 9\n",
      "[Epoch 9/20] [Batch 6/7] [Loss: 0.135312 (0.102170)]Validation loss decreased (0.108138 --> 0.102170).  Saving model ...\n",
      "Epoch: 10\n",
      "[Epoch 10/20] [Batch 6/7] [Loss: 0.099164 (0.100113)]Validation loss decreased (0.102170 --> 0.100113).  Saving model ...\n",
      "Epoch: 11\n",
      "[Epoch 11/20] [Batch 6/7] [Loss: 0.136309 (0.102088)]EarlyStopping counter: 1 out of 3\n",
      "Epoch: 12\n",
      "[Epoch 12/20] [Batch 6/7] [Loss: 0.161490 (0.101634)]EarlyStopping counter: 2 out of 3\n",
      "Epoch: 13\n",
      "[Epoch 13/20] [Batch 6/7] [Loss: 0.181568 (0.102292)]EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainCNN(model,dataloaders,20,optimizer,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict on Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_REG(test_loader, model, criterion,device=0):\n",
    "    \n",
    "    test_loss = []\n",
    "    predictions = []\n",
    "    ytest  = []\n",
    "    predictions_dance, y_test_dance = [], []\n",
    "    model.eval()\n",
    "    model.to(0)\n",
    "    for i_batch, data_batched in enumerate(test_loader, 0):\n",
    "        data_batched[0], data_batched[2] = data_batched[0].to(0), data_batched[2].to(0)\n",
    "        output = model(data_batched[0]).to(0)\n",
    "        \n",
    "        predictions_val , predictions_en , predictions_dance = output.squeeze()[:,0],output.squeeze()[:,1],output.squeeze()[:,2]\n",
    "        y_test_val , y_test_en , y_test_dance =  data_batched[1][:,0].to(device),data_batched[1][:,1].to(device),data_batched[1][:,2].to(device)\n",
    "        \n",
    "        loss_valence= criterion(predictions_val,   y_test_val)\n",
    "        loss_energy = criterion(predictions_en,    y_test_en)\n",
    "        loss_dance  = criterion(predictions_dance, y_test_dance)\n",
    "        \n",
    "        loss = torch.sum(torch.stack([loss_valence,loss_energy,loss_dance]))\n",
    "        test_loss.append(loss.item()) \n",
    "        \n",
    "        preds1 = predictions_val.data.cpu().numpy()\n",
    "        preds2 = predictions_en.data.cpu().numpy()\n",
    "        preds3 = predictions_dance.data.cpu().numpy()\n",
    "        \n",
    "        predictions += list(preds1)\n",
    "        predictions += list(preds2)\n",
    "        predictions += list(preds3)\n",
    "    \n",
    "        ytest += list(y_test_val.data.cpu().numpy())  \n",
    "        ytest += list(y_test_en.data.cpu().numpy()) \n",
    "        ytest += list(y_test_dance.data.cpu().numpy()) \n",
    "        \n",
    "    total_loss = np.mean(test_loss)\n",
    "    print('Test loss: {}'.format(total_loss))\n",
    "    return predictions, ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.1002211103008853\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SpearmanrResult(correlation=0.6823570879523527, pvalue=0.0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion_regr = nn.MSELoss()\n",
    "predictions_cnn, labels_cnn = CNN_REG(test_loader, model, criterion_regr)\n",
    "spearmanr(labels_cnn, predictions_cnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Παρατηρούμε πως πετύχαμε loss περίπου 0.1 με καλό correlation το οποίο είναι στατιστικά σημαντικό."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
